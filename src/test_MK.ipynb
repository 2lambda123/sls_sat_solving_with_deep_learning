{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "def one_hot(x, k, dtype=jnp.float32):\n",
    "    \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
    "    return jnp.array(x[:, None] == jnp.arange(k), dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([0,0,0,0,1,1,1])\n",
    "k=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[1., 0.],\n",
       "             [1., 0.],\n",
       "             [1., 0.],\n",
       "             [1., 0.],\n",
       "             [0., 1.],\n",
       "             [0., 1.],\n",
       "             [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(x,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pysat.formula import CNF\n",
    "def do_it(instance_name):\n",
    "        #cnf = CNF(from_file=(instance_name + \".cnf\"))\n",
    "        #print(cnf.clauses[0][0])\n",
    "\n",
    "        target_name = instance_name + \"_samples_sol.npy\"\n",
    "        target_func=np.load(target_name)\n",
    "\n",
    "\n",
    "        #number_of_unsat=check_clauses(cnf.clauses,target_func)\n",
    "        #print(number_of_unsat)\n",
    "        #, target_func),axis=0)\n",
    "        #print(violated_constraints_for_candidates)\n",
    "        weights= 1#tbf    \n",
    "        return((target_func,weights))\n",
    "\n",
    "def assignment(x):\n",
    "    if x > 0:\n",
    "        return False\n",
    "    elif x < 0:\n",
    "        return True\n",
    "    else:\n",
    "        print(\"error, not a proper input\")\n",
    "\n",
    "def current_assignment(candidate, index):\n",
    "        return candidate[index]\n",
    "\n",
    "def check_clauses(clauses,candidate):\n",
    "        count_unsat=0\n",
    "        print(clauses[0][0])\n",
    "        for i in range(len(clauses)):\n",
    "                satisfied=0\n",
    "                for j in range(len(clauses[i])):\n",
    "                        if satisfied==0:\n",
    "                                desired=assignment(clauses[i][j])\n",
    "                                print(\"a\",desired)\n",
    "                                current= current_assignment(candidate[i],j)\n",
    "                                print(\"b\",current)\n",
    "                                if desired==current:\n",
    "                                        satisfied=1\n",
    "                        if satisfied==0:\n",
    "                                count_unsat+= 1\n",
    "        return count_unsat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_name=\"/Users/p403830/Library/CloudStorage/OneDrive-PorscheDigitalGmbH/programming/ml_based_sat_solver/git_multiple_candidates/ml_based_sat_solver/Data/one_example/41-20486\"\n",
    "\n",
    "a=do_it(instance_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[False, False, False, ..., False, False, False],\n",
      "       [ True,  True,  True, ..., False, False, False],\n",
      "       [False, False,  True, ..., False,  True, False],\n",
      "       ...,\n",
      "       [False, False,  True, ...,  True,  True,  True],\n",
      "       [False,  True, False, ...,  True, False,  True],\n",
      "       [False,  True,  True, ...,  True,  True,  True]]), 1)\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import gzip\n",
    "from os.path import join, exists, splitext\n",
    "import pickle\n",
    "\n",
    "import jraph\n",
    "import nnf\n",
    "from func_timeout import func_timeout, FunctionTimedOut\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "from pysat.formula import CNF\n",
    "from collections import namedtuple\n",
    "from constraint_problems import get_problem_from_cnf\n",
    "from random_walk import violated_constraints\n",
    "from jax import vmap\n",
    "\n",
    "\n",
    "def create_candidates_with_sol(data_dir, sample_size, threshold):\n",
    "    solved_instances = glob.glob(join(data_dir, \"*_sol.pkl\"))\n",
    "    for g in solved_instances:\n",
    "        with open(g, \"rb\") as f:\n",
    "            p = pickle.load(f)\n",
    "        n = np.array(list(p.values()), dtype=bool)\n",
    "        samples = sample_candidates(n, sample_size-1, threshold)\n",
    "        #print(samples)\n",
    "        samples = np.concatenate((np.reshape(n,(1,len(n))),samples),axis=0)\n",
    "        name = g.split('_sol.pkl')[0]\n",
    "        with open(name + \"_samples_sol.npy\", \"wb\") as f:\n",
    "            np.save(f, samples)\n",
    "    #return(samples)\n",
    "\n",
    "\n",
    "\n",
    "def sample_candidates(original, sample_size, threshold):\n",
    "    np.random.seed(sum(original))\n",
    "    condition = np.random.random((sample_size, original.shape[0])) < threshold\n",
    "    return np.where(condition, np.invert(original), original)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_dir=\"/Users/p403830/Library/CloudStorage/OneDrive-PorscheDigitalGmbH/programming/ml_based_sat_solver/BroadcastTestSet_subset\"\n",
    "sample_size=20\n",
    "threshold=0.5\n",
    "\n",
    "create_candidates_with_sol(data_dir, sample_size, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'problem' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_5/jp84zrhn28sg9yqq0sq0dkfr0000gp/T/ipykernel_47023/1762438661.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mviolated_constraints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mvio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber_of_violated_constraints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'problem' is not defined"
     ]
    }
   ],
   "source": [
    "from random_walk import violated_constraints\n",
    "import numpy as np\n",
    "\n",
    "def number_of_violated_constraints(problem,candidate):\n",
    "    return np.sum(violated_constraints(problem, candidate).astype(int),axis=0)\n",
    "\n",
    "vio=number_of_violated_constraints(problem, candidates[0])\n",
    "print(vio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import vmap\n",
    "a=vmap(number_of_violated_constraints,in_axes=(None,0),out_axes=0)(problem,candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data sucessfully\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import optax\n",
    "import haiku as hk\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from torch.utils import data\n",
    "\n",
    "from data_utils import SATTrainingDataset, JraphDataLoader\n",
    "from model import network_definition    \n",
    "    \n",
    "path='/Users/p403830/Library/CloudStorage/OneDrive-PorscheDigitalGmbH/programming/ml_based_sat_solver/BroadcastTestSet_subset/'\n",
    "sat= SATTrainingDataset(path)\n",
    "print(\"loaded data sucessfully\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 14:29:32.919845: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 1s:\n",
      "\n",
      "  slice.62 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2022-12-13 14:29:33.804350: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 1.884605s\n",
      "Constant folding an instruction is taking > 1s:\n",
      "\n",
      "  slice.62 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new method\n",
      "[array([[False, False, False, ..., False, False, False],\n",
      "       [False,  True, False, ..., False, False,  True],\n",
      "       [False,  True,  True, ...,  True, False,  True],\n",
      "       ...,\n",
      "       [False,  True, False, ..., False,  True, False],\n",
      "       [ True, False, False, ...,  True,  True,  True],\n",
      "       [ True,  True,  True, ..., False, False,  True]]), DeviceArray([    1, 71330, 70546, 72344, 72796, 74300, 72189, 71263,\n",
      "             72476, 72620, 72812, 72016, 72276, 71392, 73341, 72951,\n",
      "             71868, 72936, 72676, 72900], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "problem=sat[0][0]\n",
    "candidates=sat[0][1][0:2]\n",
    "#weights=sat[2][2]\n",
    "#print(weights)\n",
    "#print(sat[0][0])\n",
    "print(candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1 71330 70546 72344 72796 74300 72189 71263 72476 72620 72812 72016\n",
      " 72276 71392 73341 72951 71868 72936 72676 72900]\n"
     ]
    }
   ],
   "source": [
    "print(candidates[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 16:41:18.780588: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 1s:\n",
      "\n",
      "  slice.62 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2022-12-13 16:41:19.849534: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2.068997s\n",
      "Constant folding an instruction is taking > 1s:\n",
      "\n",
      "  slice.62 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import optax\n",
    "import haiku as hk\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from torch.utils import data\n",
    "\n",
    "from data_utils import SATTrainingDataset, JraphDataLoader\n",
    "from model import network_definition\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "f=0.1\n",
    "\n",
    "# # Make a batched version of the forwarding\n",
    "# batched_predict = jax.vmap(network.apply, in_axes=(None, 0))\n",
    "\n",
    "\n",
    "# def loss(params, problems, targets):\n",
    "#     preds = batched_predict(params, problems)\n",
    "#     return -jnp.mean(preds * targets)\n",
    "\n",
    "\n",
    "def one_hot(x, k, dtype=jnp.float32):\n",
    "    \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
    "    return jnp.array(x[:, None] == jnp.arange(k), dtype)\n",
    "\n",
    "\n",
    "path='/Users/p403830/Library/CloudStorage/OneDrive-PorscheDigitalGmbH/programming/ml_based_sat_solver/BroadcastTestSet_subset/'\n",
    "sat_data = SATTrainingDataset(path)\n",
    "train_data, test_data = data.random_split(sat_data, [0.8, 0.2])\n",
    "\n",
    "train_loader = JraphDataLoader(train_data, batch_size=4, shuffle=True)\n",
    "\n",
    "network = hk.without_apply_rng(hk.transform(network_definition))\n",
    "params = network.init(jax.random.PRNGKey(42), sat_data[0][0].graph)\n",
    "\n",
    "opt_init, opt_update = optax.adam(1e-3)\n",
    "opt_state = opt_init(params)\n",
    "\n",
    "@jax.jit\n",
    "def update(params, opt_state, x, y):\n",
    "        #g = jax.grad(prediction_loss)(params, *x, y)\n",
    "\n",
    "        #TBD!!! -> change this function here\n",
    "\n",
    "        g=jax.grad(new_prediction_loss)(params, *x, y)\n",
    "\n",
    "        ####\n",
    "\n",
    "        updates, opt_state = opt_update(g, opt_state)\n",
    "        return optax.apply_updates(params, updates), opt_state\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def prediction_loss(params, mask, graph, solution):\n",
    "        decoded_nodes = network.apply(params, graph)\n",
    "        solution = one_hot(solution, 2)\n",
    "        # We interpret the decoded nodes as a pair of logits for each node.\n",
    "        log_prob = jax.nn.log_softmax(decoded_nodes) * solution\n",
    "        return -jnp.sum(log_prob * mask[:, None]) / jnp.sum(mask)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def new_prediction_loss(params, graph, candidates, f: float):\n",
    "            decoded_nodes = network.apply(params, graph)\n",
    "            candidates = one_hot(candidates, 2)\n",
    "            # We interpret the decoded nodes as a pair of logits for each node.\n",
    "            log_prob = jax.nn.log_softmax(decoded_nodes) * candidates[0]\n",
    "            weights = jax.nn.softmax(- f * candidates[1])\n",
    "            weighted_log_probs = jnp.dot(log_prob, weights)\n",
    "            return -weighted_log_probs\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    # batched_loss = jax.vmap(prediction_loss, in_axes=(None, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 15:14:34.515162: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 2s:\n",
      "\n",
      "  slice.62 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2022-12-13 15:14:34.608136: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2.097126s\n",
      "Constant folding an instruction is taking > 2s:\n",
      "\n",
      "  slice.62 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:1970: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.shape(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<data_utils.JraphDataLoader object at 0x7f88d3d74b80>\n"
     ]
    }
   ],
   "source": [
    "print(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 18544 and the array at index 1 has size 12112",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_5/jp84zrhn28sg9yqq0sq0dkfr0000gp/T/ipykernel_49188/816312584.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/CloudStorage/OneDrive-PorscheDigitalGmbH/GIT_SAT_ML/ml_based_sat_solver/src/data_utils.py\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menergies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproblems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menergies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 18544 and the array at index 1 has size 12112"
     ]
    }
   ],
   "source": [
    "for (x,y) in train_loader:\n",
    "    print(np.shape(x))\n",
    "    print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Entering training loop\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "        start_time = time.time()\n",
    "        for (x, y) in train_loader:\n",
    "            params, opt_state = update(params, opt_state, x, y)\n",
    "            # print(f\"{batch} done\")\n",
    "        epoch_time = time.time() - start_time\n",
    "\n",
    "        # train_acc = accuracy(params, train_images, train_labels)\n",
    "        # test_acc = accuracy(params, test_images, test_labels)\n",
    "        print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
    "\n",
    "        #test_acc = jnp.mean(jnp.asarray([prediction_loss(params, p.mask, p.graph, s) for (p, s) in test_data]))\n",
    "\n",
    "        #TBD!!!\n",
    "\n",
    "        test_acc = jnp.mean(jnp.asarray([new_prediction_loss(p, p.graph, c, f) for (p, c) in test_data]))\n",
    "        \n",
    "        ##\n",
    "\n",
    "        # print(\"Training set accuracy {}\".format(train_acc))\n",
    "        print(\"Test set accuracy {}\".format(test_acc))\n",
    "\n",
    "    # TODO: Save the model here\n",
    "\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
