{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 15:33:35.159378: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 1s:\n",
      "\n",
      "  slice.62 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2022-12-22 15:33:35.922092: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 1.765296s\n",
      "Constant folding an instruction is taking > 1s:\n",
      "\n",
      "  slice.62 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import optax\n",
    "import haiku as hk\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "from data_utils import SATTrainingDataset, JraphDataLoader\n",
    "from model import network_definition\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "f=0.0001\n",
    "\n",
    "# # Make a batched version of the forwarding\n",
    "# batched_predict = jax.vmap(network.apply, in_axes=(None, 0))\n",
    "\n",
    "\n",
    "# def loss(params, problems, targets):\n",
    "#     preds = batched_predict(params, problems)\n",
    "#     return -jnp.mean(preds * targets)\n",
    "\n",
    "\n",
    "def one_hot(x, k, dtype=jnp.float32):\n",
    "    \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
    "    return jnp.array(x[:, None] == jnp.arange(k), dtype)\n",
    "\n",
    "vmap_one_hot=jax.vmap(one_hot, in_axes=(0,None), out_axes=0)\n",
    "\n",
    "path='/Users/p403830/Library/CloudStorage/OneDrive-PorscheDigitalGmbH/programming/ml_based_sat_solver/BroadcastTestSet_subset/'\n",
    "sat_data = SATTrainingDataset(path)\n",
    "train_data, test_data = data.random_split(sat_data, [0.8, 0.2])\n",
    "\n",
    "train_loader = JraphDataLoader(train_data, batch_size=2, shuffle=True)\n",
    "\n",
    "network = hk.without_apply_rng(hk.transform(network_definition))\n",
    "params = network.init(jax.random.PRNGKey(42), sat_data[0][0].graph)\n",
    "\n",
    "opt_init, opt_update = optax.adam(1e-3)\n",
    "opt_state = opt_init(params)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def compute_log_probs(decoded_nodes, mask, candidate):\n",
    "            a=jax.nn.log_softmax(decoded_nodes) * mask[:, None]\n",
    "            b= jnp.dot(candidate,a.T)\n",
    "            return b\n",
    "\n",
    "\n",
    "vmap_compute_log_probs=jax.vmap(compute_log_probs, in_axes=(None,None, 0), out_axes=0)\n",
    "\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def update(params, opt_state, x, y, f):\n",
    "            batch_masks=x[0]\n",
    "            batch_graphs=x[1]\n",
    "            batch_c=y[0]\n",
    "            batch_e=y[1]\n",
    "            #print(len(batch_masks))\n",
    "            #print(len(batch_graphs))\n",
    "            #print(len(batch_c))\n",
    "            #print(len(batch_e))\n",
    "            #print(batch_e[0])\n",
    "            #print(batch_e)\n",
    "            #loss=new_prediction_loss(params, batch_masks[0], batch_graphs[0], batch_c[0], batch_e[0], f)\n",
    "            #print(loss)\n",
    "            g=jax.grad(new_prediction_loss)(params, batch_masks[0], batch_graphs[0], batch_c[0], batch_e[0], f)\n",
    "            #g=jax.grad(batched_loss)(params, *x, c, e, f)\n",
    "            ####\n",
    "            updates, opt_state = opt_update(g, opt_state)\n",
    "            return optax.apply_updates(params, updates), opt_state\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def prediction_loss(params, mask, graph, solution):\n",
    "        decoded_nodes = network.apply(params, graph)\n",
    "        solution = one_hot(solution, 2)\n",
    "        # We interpret the decoded nodes as a pair of logits for each node.\n",
    "        log_prob = jax.nn.log_softmax(decoded_nodes) * solution\n",
    "        return -jnp.sum(log_prob * mask[:, None]) / jnp.sum(mask)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def new_prediction_loss(params, mask, graph, candidates, energies, f: float):\n",
    "            decoded_nodes = network.apply(params, graph)\n",
    "            candidates = vmap_one_hot(candidates, 2)\n",
    "            log_prob=vmap_compute_log_probs(decoded_nodes, mask, candidates)\n",
    "            weights = jax.nn.softmax(- f * energies)\n",
    "            #print(np.shape(weights))\n",
    "            weighted_log_probs = jax.vmap(jnp.dot,axis_name=(0,0), out_axes=0)(log_prob, weights)\n",
    "            #print(np.shape(weighted_log_probs))\n",
    "            summed_weighted_log_probs=jnp.sum(weighted_log_probs, axis=0) #sum over all candidates\n",
    "            #print(np.shape(summed_weighted_log_probs))\n",
    "            #loss=1\n",
    "            #print(np.shape(summed_weighted_log_probs))\n",
    "            #print(np.shape(mask[:,None]))\n",
    "            a=jnp.dot(summed_weighted_log_probs ,mask[:, None])\n",
    "            #b=jnp.asarray(a)\n",
    "            #print(b)\n",
    "            loss=-jnp.sum(a, axis=0) / jnp.sum(mask)\n",
    "            #print(loss)\n",
    "            #print(np.shape(loss))\n",
    "            #print(loss)\n",
    "            return loss#summed_weighted_log_probs#loss\n",
    "\n",
    "#@jax.jit\n",
    "def batched_loss_slow(params, batch_masks, batch_graphs, batch_candidates, batch_energies, f: float):\n",
    "            batchsize=len(batch_energies)\n",
    "            loss_vec=np.zeros(batchsize)\n",
    "            for l in range(batchsize):\n",
    "                loss_vec[l]=new_prediction_loss(params, batch_masks[l], batch_graphs[l], batch_candidates[l], batch_energies[l], f)\n",
    "            #print(loss_vec)\n",
    "            loss_sum=jnp.sum(loss_vec)/batchsize\n",
    "            return loss_sum\n",
    "\n",
    "\n",
    "#batched_loss = jax.vmap(new_prediction_loss, in_axes=(0, 0, 0, 0,0, None), out_axes=0)\n",
    "#batched_loss = jax.vmap(new_prediction_loss_single, in_axes=(None, None, None, 1,1, None), out_axes=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_number 1\n"
     ]
    }
   ],
   "source": [
    "##works (if we do not use @jax.jit for the definition of batched_loss_slow(.))\n",
    "\n",
    "counter=0\n",
    "for (batch_p, batch_ce) in train_loader:\n",
    "            counter=counter+1\n",
    "            print(\"batch_number\", counter)\n",
    "            batch_masks=batch_p[0]\n",
    "            batch_graphs=batch_p[1]\n",
    "            batch_c=batch_ce[0]\n",
    "            batch_e=batch_ce[1]\n",
    "            loss=batched_loss_slow(params, batch_masks, batch_graphs, batch_c, batch_e, f)\n",
    "            print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_number 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "vmap got inconsistent sizes for array axes to be mapped:\n  * most axes (7 of them) had size 2, e.g. axis 0 of argument graph[0].n_node of type int32[2];\n  * some axes (6 of them) had size 800074, e.g. axis 0 of argument graph[0].edges of type float32[800074,2];\n  * some axes (4 of them) had size 411468, e.g. axis 0 of argument mask[0] of type int32[411468]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/_5/jp84zrhn28sg9yqq0sq0dkfr0000gp/T/ipykernel_3643/2595261161.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     18\u001B[0m             \u001B[0;31m#    loss_vec[i]=new_prediction_loss(params, batch_masks[i], batch_graphs[i], batch_c[i], batch_e[i], f)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m             \u001B[0mloss_vec\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mjax\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnew_prediction_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0min_axes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mout_axes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_masks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_graphs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_c\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_e\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     21\u001B[0m             \u001B[0mloss_sum\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mjnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss_vec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0mbatchsize\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss_sum\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "    \u001B[0;31m[... skipping hidden 2 frame]\u001B[0m\n",
      "\u001B[0;32m/Applications/anaconda3/lib/python3.9/site-packages/jax/_src/api.py\u001B[0m in \u001B[0;36m_mapped_axis_size\u001B[0;34m(fn, tree, vals, dims, name)\u001B[0m\n\u001B[1;32m   1752\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1753\u001B[0m       \u001B[0mmsg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"  * some axes ({ct} of them) had size {sz}, e.g. axis {ax} of {ex};\\n\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1754\u001B[0;31m   \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m''\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# remove last semicolon and newline\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1755\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1756\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: vmap got inconsistent sizes for array axes to be mapped:\n  * most axes (7 of them) had size 2, e.g. axis 0 of argument graph[0].n_node of type int32[2];\n  * some axes (6 of them) had size 800074, e.g. axis 0 of argument graph[0].edges of type float32[800074,2];\n  * some axes (4 of them) had size 411468, e.g. axis 0 of argument mask[0] of type int32[411468]"
     ]
    }
   ],
   "source": [
    "##works but it is slow...\n",
    "counter=0\n",
    "for (batch_p, batch_ce) in train_loader:\n",
    "            counter=counter+1\n",
    "            print(\"batch_number\", counter)\n",
    "            batch_masks=batch_p[0]\n",
    "            batch_graphs=batch_p[1]\n",
    "            batch_c=batch_ce[0]\n",
    "            batch_e=batch_ce[1]\n",
    "            #print(batch_masks[0])\n",
    "            #print(batch_graphs[0])\n",
    "            #print(batch_c[0])\n",
    "            #print(batch_e)\n",
    "            #print(batch_e[0])\n",
    "            batchsize=len(batch_e)\n",
    "            loss_vec=np.zeros(batchsize)\n",
    "            for i in range(batchsize):\n",
    "                loss_vec[i]=new_prediction_loss(params, batch_masks[i], batch_graphs[i], batch_c[i], batch_e[i], f)\n",
    "            \n",
    "            #loss_vec=jax.vmap(new_prediction_loss, in_axes=(None,0,0,0,0,None),out_axes=0)(params, batch_masks, batch_graphs, batch_c, batch_e, f)\n",
    "            loss_sum=jnp.sum(loss_vec)/batchsize\n",
    "            print(loss_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##this works now!!! :)\n",
    "counter=0\n",
    "for (batch_p, batch_ce) in train_loader:\n",
    "            counter=counter+1\n",
    "            print(\"batch_number\", counter)\n",
    "            batch_masks=batch_p[0]\n",
    "            batch_graphs=batch_p[1]\n",
    "            batch_c=batch_ce[0]\n",
    "            batch_e=batch_ce[1]\n",
    "            loss=new_prediction_loss(params, batch_masks[0], batch_graphs[0], batch_c[0], batch_e[0], f)\n",
    "            print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_number 1\n",
      "[0.8581489  0.14185107]\n",
      "(13262, 1)\n",
      "[9274.2705]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 15:43:52.783090: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 2s:\n",
      "\n",
      "  slice.60 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2022-12-20 15:43:52.806034: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2.025561s\n",
      "Constant folding an instruction is taking > 2s:\n",
      "\n",
      "  slice.60 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_number 2\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "##this works, but is only done in small steps...\n",
    "counter=0\n",
    "for (batch_p, batch_ce) in train_loader:\n",
    "            counter=counter+1\n",
    "            print(\"batch_number\", counter)\n",
    "            batch_masks=batch_p[0]\n",
    "            batch_graphs=batch_p[1]\n",
    "            batch_c=batch_ce[0]\n",
    "            batch_e=batch_ce[1]\n",
    "            #print(len(batch_masks))\n",
    "            #print(len(batch_graphs))\n",
    "            #print(len(batch_c))\n",
    "            #print(len(batch_e))\n",
    "            #print(batch_e)\n",
    "            mask = batch_masks[0]\n",
    "            graph = batch_graphs[0]\n",
    "            c = batch_c[0]\n",
    "            e= batch_e[0]\n",
    "            #print(e)\n",
    "            f=0.01\n",
    "            decoded_nodes = network.apply(params, graph)\n",
    "            candidates = vmap_one_hot(c, 2)\n",
    "            #log_prob=compute_log_probs(decoded_nodes, mask, candidates[0])\n",
    "            #log_prob= jax.vmap(compute_log_probs, in_axes=(None,None, 0), out_axes=0)(decoded_nodes, mask, candidates)\n",
    "            log_prob=vmap_compute_log_probs(decoded_nodes, mask, candidates)\n",
    "            weights = jax.nn.softmax(- f * e)\n",
    "            #weights= scipy.special.softmax(-f*e)\n",
    "            print(weights)\n",
    "            #print(np.shape(weights))\n",
    "            weighted_log_probs = jax.vmap(jnp.dot,axis_name=(0,0), out_axes=0)(log_prob, weights)\n",
    "            #print(np.shape(weighted_log_probs))\n",
    "            summed_weighted_log_probs=jnp.sum(weighted_log_probs, axis=0) #sum over all candidates\n",
    "            #print(np.shape(summed_weighted_log_probs))\n",
    "            #print(summed_weighted_log_probs)\n",
    "            #loss=1\n",
    "            #print(np.shape(summed_weighted_log_probs))\n",
    "            #print(np.shape(mask[:,None]))\n",
    "            a=jnp.dot(summed_weighted_log_probs ,mask[:, None])\n",
    "            #b=jnp.asarray(a)\n",
    "            print(np.shape(a))\n",
    "            #print(b)\n",
    "            loss=-jnp.sum(a,axis=0) / jnp.sum(mask)\n",
    "            print(loss)\n",
    "\n",
    "\n",
    "\n",
    "            #loss=new_prediction_loss(params, batch_masks[0], batch_graphs[0], batch_c[0], batch_e[0], f)\n",
    "            #print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute '_replace'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/_5/jp84zrhn28sg9yqq0sq0dkfr0000gp/T/ipykernel_4535/1211893448.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0;31m#print(e)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0mf\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.01\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m     \u001B[0mdecoded_nodes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnetwork\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgraph\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m     \u001B[0mcandidates\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvmap_one_hot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0;31m#log_prob=compute_log_probs(decoded_nodes, mask, candidates[0])\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Applications/anaconda3/lib/python3.9/site-packages/haiku/_src/multi_transform.py\u001B[0m in \u001B[0;36mapply_fn\u001B[0;34m(params, *args, **kwargs)\u001B[0m\n\u001B[1;32m    296\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mapply_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    297\u001B[0m       \u001B[0mcheck_rng_kwarg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 298\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    299\u001B[0m     \u001B[0mf_new\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhk\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTransformed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minit\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minit\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mapply\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mapply_fn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    300\u001B[0m     \u001B[0m_transform\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtie_in_original_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf_new\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minit\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf_new\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Applications/anaconda3/lib/python3.9/site-packages/haiku/_src/transform.py\u001B[0m in \u001B[0;36mapply_fn\u001B[0;34m(params, *args, **kwargs)\u001B[0m\n\u001B[1;32m    126\u001B[0m           \"name (e.g. `f.apply(.., state=my_state)`)\")\n\u001B[1;32m    127\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 128\u001B[0;31m     \u001B[0mout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstate\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    129\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mstate\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    130\u001B[0m       raise ValueError(\"If your transformed function uses `hk.{get,set}_state` \"\n",
      "\u001B[0;32m/Applications/anaconda3/lib/python3.9/site-packages/haiku/_src/transform.py\u001B[0m in \u001B[0;36mapply_fn\u001B[0;34m(params, state, rng, *args, **kwargs)\u001B[0m\n\u001B[1;32m    355\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mbase\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnew_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstate\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrng\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrng\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mctx\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    356\u001B[0m       \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 357\u001B[0;31m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    358\u001B[0m       \u001B[0;32mexcept\u001B[0m \u001B[0mjax\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0merrors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mUnexpectedTracerError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    359\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mjax\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0merrors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mUnexpectedTracerError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0munexpected_tracer_hint\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/CloudStorage/OneDrive-PorscheDigitalGmbH/GIT_SAT_ML/ml_based_sat_solver/src/model.py\u001B[0m in \u001B[0;36mnetwork_definition\u001B[0;34m(graph, num_message_passing_steps)\u001B[0m\n\u001B[1;32m     24\u001B[0m         \u001B[0membed_node_fn\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mjax\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhk\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m16\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m     )\n\u001B[0;32m---> 26\u001B[0;31m     \u001B[0mgraph\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0membedding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgraph\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mmlp\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdims\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Applications/anaconda3/lib/python3.9/site-packages/jraph/_src/models.py\u001B[0m in \u001B[0;36mEmbed\u001B[0;34m(graphs_tuple)\u001B[0m\n\u001B[1;32m    328\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    329\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mEmbed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgraphs_tuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 330\u001B[0;31m     return graphs_tuple._replace(\n\u001B[0m\u001B[1;32m    331\u001B[0m         \u001B[0mnodes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0membed_nodes_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgraphs_tuple\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnodes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    332\u001B[0m         \u001B[0medges\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0membed_edges_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgraphs_tuple\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0medges\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'numpy.ndarray' object has no attribute '_replace'"
     ]
    }
   ],
   "source": [
    "test_acc_now=[]\n",
    "for (p, ce) in test_data:\n",
    "    mask = p[0]\n",
    "    graph = p[1]\n",
    "    c = ce[0]\n",
    "    e= ce[1]\n",
    "    #print(e)\n",
    "    f=0.01\n",
    "    decoded_nodes = network.apply(params, graph)\n",
    "    candidates = vmap_one_hot(c, 2)\n",
    "    #log_prob=compute_log_probs(decoded_nodes, mask, candidates[0])\n",
    "    #log_prob= jax.vmap(compute_log_probs, in_axes=(None,None, 0), out_axes=0)(decoded_nodes, mask, candidates)\n",
    "    log_prob=vmap_compute_log_probs(decoded_nodes, mask, candidates)\n",
    "    weights = jax.nn.softmax(- f * e)\n",
    "    #weights= scipy.special.softmax(-f*e)\n",
    "    print(weights)\n",
    "    #print(np.shape(weights))\n",
    "    weighted_log_probs = jax.vmap(jnp.dot,axis_name=(0,0), out_axes=0)(log_prob, weights)\n",
    "    #print(np.shape(weighted_log_probs))\n",
    "    summed_weighted_log_probs=jnp.sum(weighted_log_probs, axis=0) #sum over all candidates\n",
    "    #print(np.shape(summed_weighted_log_probs))\n",
    "    #print(summed_weighted_log_probs)\n",
    "    #loss=1\n",
    "    #print(np.shape(summed_weighted_log_probs))\n",
    "    #print(np.shape(mask[:,None]))\n",
    "    a=jnp.dot(summed_weighted_log_probs ,mask[:, None])\n",
    "    #b=jnp.asarray(a)\n",
    "    print(np.shape(a))\n",
    "    #print(b)\n",
    "    loss=-jnp.sum(a,axis=0) / jnp.sum(mask)\n",
    "    print(loss)\n",
    "    #loss=new_prediction_loss(params, p[0], p[1], ce[0],ce[1] , f)\n",
    "    #print(loss)\n",
    "print(test_acc_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=1\n",
    "print(np.shape(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@jax.jit()\n",
    "def test_loss(params, graph, mask, candidates, energies):\n",
    "    decoded_nodes = network.apply(params, graph)\n",
    "    candidates = vmap_one_hot(candidates, 2)\n",
    "    log_prob=vmap_compute_log_probs(decoded_nodes, mask, candidates)\n",
    "    weights = jax.nn.softmax(- f * energies)\n",
    "    weighted_log_probs = jax.vmap(jnp.dot,axis_name=(0,0), out_axes=0)(log_prob, weights)\n",
    "    summed_weighted_log_probs=np.sum(weighted_log_probs, axis=0) #sum over all candidates\n",
    "    loss=-jnp.sum(summed_weighted_log_probs @ mask[:, None]) / jnp.sum(mask)\n",
    "    #print(np.shape(loss))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test_acc_now=[]\n",
    "for (p, ce) in test_data:\n",
    "    graph=p[0]\n",
    "    mask=p[1]\n",
    "    candidates=ce[0]\n",
    "    energies=ce[1]\n",
    "    '''\n",
    "    decoded_nodes = network.apply(params, graph)\n",
    "    print(np.shape(decoded_nodes))\n",
    "    candidates = vmap_one_hot(candidates, 2)\n",
    "    log_prob=vmap_compute_log_probs(decoded_nodes, mask, candidates)\n",
    "    weights = jax.nn.softmax(- f * energies)\n",
    "    weighted_log_probs = jax.vmap(jnp.dot,axis_name=(0,0), out_axes=0)(log_prob, weights)\n",
    "    summed_weighted_log_probs=np.sum(weighted_log_probs, axis=0) #sum over all candidates\n",
    "    loss=-jnp.sum(summed_weighted_log_probs @ mask[:, None]) / jnp.sum(mask)\n",
    "    '''\n",
    "    loss=test_loss(params, graph, mask, candidates, energies)\n",
    "    print(loss)\n",
    "\n",
    "#test_acc_list.append(jnp.mean(test_acc_now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}